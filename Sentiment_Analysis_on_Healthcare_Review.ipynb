{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619dea42-85d4-42e8-80c9-11a1aa330bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Five row of Dataset\n",
      "                                         Review_Text  Rating\n",
      "0        I have mixed feelings about my experience.        4\n",
      "1  The staff was caring and attentive. I couldn't...       5\n",
      "2        I have mixed feelings about my experience.        5\n",
      "3        I have mixed feelings about my experience.        5\n",
      "4  The healthcare provider was excellent. I had a...       3\n",
      "\n",
      "Missing Values\n",
      "Review_Text    100\n",
      "Rating           0\n",
      "dtype: int64\n",
      "\n",
      "Shape of Dataset: (1000, 2)\n",
      "\n",
      " information of Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Review_Text  900 non-null    object\n",
      " 1   Rating       1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a dataset\n",
    "df = pd.read_csv(r\"C:\\Project_Guvi\\MDE93\\healthcare_reviews.csv\")\n",
    "\n",
    "#  first few rows of the dataset\n",
    "print(\"First Five row of Dataset\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Shape of dataset\n",
    "print(\"\\nShape of Dataset:\",df.shape)\n",
    "\n",
    "#info\n",
    "print(\"\\n information of Dataset\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48e4608-5c90-467c-8266-a7e4a22a0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing value in review_text column\n",
    "df = df.dropna(subset=['Review_Text'])\n",
    "\n",
    "# Define a function to categorize ratings into sentiment labels\n",
    "def sentiment_label(rating):\n",
    "    if rating >= 4:\n",
    "        return '2' #Positive\n",
    "    elif rating == 3:\n",
    "        return '1' #neutral\n",
    "    else:\n",
    "        return '0' # negative\n",
    "\n",
    "# Apply the function to create a new column 'Sentiment'\n",
    "df['Sentiment'] = df['Rating'].apply(sentiment_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa8e88a-e72e-4f19-a3e8-7ae007350b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "2    388\n",
       "0    365\n",
       "1    147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8de3d1-dea8-4791-aa5b-57c53c80c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Project_Guvi\\MDE93\\healthcare_with_sentimentlabel.csv\",index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afdbe31-c0a8-48ca-aeab-01551ad3db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yuvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yuvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yuvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Review_Text  \\\n",
      "0        I have mixed feelings about my experience.    \n",
      "1  The staff was caring and attentive. I couldn't...   \n",
      "2        I have mixed feelings about my experience.    \n",
      "3        I have mixed feelings about my experience.    \n",
      "4  The healthcare provider was excellent. I had a...   \n",
      "\n",
      "                              Cleaned_Review_Text  \n",
      "0                        mixed feeling experience  \n",
      "1          staff caring attentive couldnt happier  \n",
      "2                        mixed feeling experience  \n",
      "3                        mixed feeling experience  \n",
      "4  healthcare provider excellent great experience  \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing to the Review_Text column\n",
    "df['Cleaned_Review_Text'] = df['Review_Text'].apply(preprocess_text)\n",
    "\n",
    "# Inspect the cleaned text\n",
    "print(df[['Review_Text', 'Cleaned_Review_Text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e09a10d-9030-4e4d-9fc1-8387aa82c09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Cleaned_Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have mixed feelings about my experience.</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed feeling experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The staff was caring and attentive. I couldn't...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>staff caring attentive couldnt happier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have mixed feelings about my experience.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed feeling experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have mixed feelings about my experience.</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>mixed feeling experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The healthcare provider was excellent. I had a...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>healthcare provider excellent great experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text  Rating Sentiment  \\\n",
       "0        I have mixed feelings about my experience.        4         2   \n",
       "1  The staff was caring and attentive. I couldn't...       5         2   \n",
       "2        I have mixed feelings about my experience.        5         2   \n",
       "3        I have mixed feelings about my experience.        5         2   \n",
       "4  The healthcare provider was excellent. I had a...       3         1   \n",
       "\n",
       "                              Cleaned_Review_Text  \n",
       "0                        mixed feeling experience  \n",
       "1          staff caring attentive couldnt happier  \n",
       "2                        mixed feeling experience  \n",
       "3                        mixed feeling experience  \n",
       "4  healthcare provider excellent great experience  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d235f32-6bd4-411a-924e-7f7961ae995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Project_Guvi\\MDE93\\healthcare_cleaned_dataset.csv\",index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b880a85d-70d1-4a5b-ab94-dc7db1cdc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "\n",
    "# Apply TF-IDF transformation\n",
    "X = tfidf.fit_transform(df['Cleaned_Review_Text'])\n",
    "\n",
    "# Convert to DataFrame for easier inspection\n",
    "X_tfidf = pd.DataFrame(X.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Inspect the transformed data\n",
    "#print(X_tfidf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc58f07-2309-4645-928a-f3bb8e56d5fc",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68deaa5-fef7-457f-a816-ed00c532624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (630, 34)\n",
      "Testing set size: (270, 34)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "X = X_tfidf\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f24bf468-f583-4a37-aae1-e4969e12fbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42592592592592593\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.45      0.46       122\n",
      "           1       1.00      0.00      0.00        34\n",
      "           2       0.40      0.53      0.45       114\n",
      "\n",
      "    accuracy                           0.43       270\n",
      "   macro avg       0.62      0.33      0.30       270\n",
      "weighted avg       0.50      0.43      0.40       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[55  0 67]\n",
      " [10  0 24]\n",
      " [54  0 60]]\n"
     ]
    }
   ],
   "source": [
    "# randomforest without smote\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the Random Forest model with optimized parameters\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,            # Reduce number of trees\n",
    "    max_depth=20,               # Limit the depth of trees\n",
    "    min_samples_split=10,       # Minimum samples required to split an internal node\n",
    "    n_jobs=-1,                  # Utilize all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d897ca99-d52c-4b1c-b980-7245e45f6627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "Best Parameters: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.3296296296296296\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.55      0.49       122\n",
      "           1       0.12      0.35      0.18        34\n",
      "           2       0.42      0.09      0.14       114\n",
      "\n",
      "    accuracy                           0.33       270\n",
      "   macro avg       0.33      0.33      0.27       270\n",
      "weighted avg       0.39      0.33      0.31       270\n",
      "\n",
      "Confusion Matrix:\n",
      "[[67 44 11]\n",
      " [19 12  3]\n",
      " [64 40 10]]\n"
     ]
    }
   ],
   "source": [
    "# randomforest with smote\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],           # Number of trees \n",
    "    'max_depth': [10, 20, None],              # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],          # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],            # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False],               # Whether bootstrap samples are used when building trees\n",
    "    'max_features': ['sqrt', 'log2', None]    # Number of features to consider for best split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Train the model using GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the original test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Output results\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1230c7-b3d9-4bdd-9031-be0ca9d50325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a122979e-39b5-4222-a3e8-e3d7caf20e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 1, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga'}\n",
      "Accuracy: 0.42592592592592593\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.45      0.46       122\n",
      "           1       0.00      0.00      0.00        34\n",
      "           2       0.40      0.53      0.45       114\n",
      "\n",
      "    accuracy                           0.43       270\n",
      "   macro avg       0.29      0.33      0.30       270\n",
      "weighted avg       0.38      0.43      0.40       270\n",
      "\n",
      "[[55  0 67]\n",
      " [10  0 24]\n",
      " [54  0 60]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# logisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': [ 'l2',  'none'],  # Penalty (regularization) options\n",
    "    'solver': ['saga'],  # Solver that supports 'l1' and 'elasticnet'\n",
    "    'max_iter': [100, 200, 500]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Train the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3975fd-bca2-4118-a0cf-2a79f5406a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
